{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Regression with Tensorflow\n",
    "\n",
    "This tutorial will show you a simple linear regression example.\n",
    "We will declare some variable X, with corresponding dependent variables Y, and try to model their relationship using linear regression.\n",
    "\n",
    "Here, first declare the packages we will be using: Tensorflow, numpy and matplotlib.pyplot. We will use numpy to create our data and generate some numbers. Matplotlib.pyplot would help us construct matlab-like plots (if you are familiar with Matlab), to plot our resulting fitted line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will declare some of the fixed parameters we will use in our learning, and plot-drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following part, we will declare our dataset. We only use one dimensional features here for X, so that we can visualize it later on in a 2-dimensional plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to the part where we will start our learning with Tensorflow. \n",
    "\n",
    "We first declare some Placeholder Tensors to represt our input data. Since they are only one dimensional, we declare their type to be a float number. \n",
    "\n",
    "Next, we will declare the Variable Tensors. This depends on the parameters we will train in our learning method.\n",
    "For our data, we will be training the following model:\n",
    "\n",
    "\\begin{equation}\n",
    "    y = W*x + b\n",
    "\\end{equation}\n",
    "\n",
    "This gives us two parameters which values we need to train, a weighting coefficient*W*, and a bias factor *b*. \n",
    "Since they will be declared as Variable Tensors, we need to give them an initial value to work on. Below, we use a randomizer to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare input data type\n",
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "\n",
    "#Declare trainable parameters\n",
    "randomizer=np.random\n",
    "W=tf.Variable(randomizer.randn(), tf.float32, name=\"weight\")\n",
    "b=tf.Variable(randomizer.randn(), tf.float32, name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After declaring our data and parameters, we move on to declaring our model, and a cost function to evaluate it against. \n",
    "\n",
    "There are different cost function that you can use. Here, we give you two examples: the sum of squares, and the mean squared error, that you can choose from.\n",
    "\n",
    "If y' is the predicted value of y given by our learned model, the sum of squares and mean squared error equations are given as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "Sum\\_of\\_squares = \\sum_{n=1}^{N} y_n'² - y_n²\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "MSE = \\frac{Sum\\_of\\_squares}{2 * N}\n",
    "\\end{equation}\n",
    "\n",
    "*N is the number of of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare model\n",
    "linear_model=tf.add(tf.mul(W,x),b) #depending on your Tensorflow version, you might need to change tf.mul to tf.multiply\n",
    "\n",
    "#Declare cost function\n",
    "loss=tf.reduce_sum(tf.square(linear_model-y)) #sum of squares\n",
    "loss_=tf.reduce_sum(tf.pow(linear_model-y,2))/(2*n_samples) #mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, we declare the method that we want to use to optimize our learning parameters. \n",
    "Here, we will use a Gradient Descent optimizer. To declare the optimizer, we need to indicate a learning rate, and associate it with the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can move on to fitting our data into a regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.081538931 W= 0.212163 b= 1.07074\n",
      "Epoch: 0100 cost= 0.081017144 W= 0.214389 b= 1.05472\n",
      "Epoch: 0150 cost= 0.080555409 W= 0.216483 b= 1.03966\n",
      "Epoch: 0200 cost= 0.080146760 W= 0.218452 b= 1.02549\n",
      "Epoch: 0250 cost= 0.079785138 W= 0.220304 b= 1.01217\n",
      "Epoch: 0300 cost= 0.079465069 W= 0.222046 b= 0.999639\n",
      "Epoch: 0350 cost= 0.079181768 W= 0.223685 b= 0.987852\n",
      "Epoch: 0400 cost= 0.078931049 W= 0.225226 b= 0.976766\n",
      "Epoch: 0450 cost= 0.078709133 W= 0.226675 b= 0.966339\n",
      "Epoch: 0500 cost= 0.078512691 W= 0.228039 b= 0.956532\n",
      "Epoch: 0550 cost= 0.078338891 W= 0.22932 b= 0.947311\n",
      "Epoch: 0600 cost= 0.078185007 W= 0.230526 b= 0.938639\n",
      "Epoch: 0650 cost= 0.078048788 W= 0.23166 b= 0.930481\n",
      "Epoch: 0700 cost= 0.077928193 W= 0.232726 b= 0.922809\n",
      "Epoch: 0750 cost= 0.077821434 W= 0.233729 b= 0.915593\n",
      "Epoch: 0800 cost= 0.077726886 W= 0.234673 b= 0.908807\n",
      "Epoch: 0850 cost= 0.077643193 W= 0.23556 b= 0.902423\n",
      "Epoch: 0900 cost= 0.077569075 W= 0.236394 b= 0.89642\n",
      "Epoch: 0950 cost= 0.077503450 W= 0.237179 b= 0.890773\n",
      "Epoch: 1000 cost= 0.077445321 W= 0.237918 b= 0.885463\n",
      "Optimization Finished!\n",
      "Training cost= 0.0774453 W= 0.237918 b= 0.885463 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "#Perform learning\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x_, y_) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, {x:x_, y:y_})\n",
    "\n",
    "    #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(loss_, feed_dict={x: train_X, y:train_Y})\n",
    "            print \"Epoch:\", '%04d' % (i+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "    training_cost = sess.run(loss_, feed_dict={x: train_X, y: train_Y})\n",
    "    print \"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n'\n",
    "\n",
    "     #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
